{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TokenLearner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMpJs0F7+X3PJCepNcGJXBC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtuUbHj0jt71"
      },
      "source": [
        "# Imports and Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmrKKlKZkbnY"
      },
      "source": [
        "! pip install -q -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsyTdBuTimEZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8EaplNdlrzI"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsr-hljfmOcb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWUI-ueYluAj"
      },
      "source": [
        "# DATA\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/ViT\"\n",
        "BUFFER_SIZE = 1024\n",
        "BATCH_SIZE = 256\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 20\n",
        "\n",
        "# AUGMENTATION\n",
        "IMAGE_SIZE = 48  # We will resize input images to this size.\n",
        "PATCH_SIZE = 6  # Size of the patches to be extracted from the input images.\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "# ViT ARCHITECTURE HYPERPARAMETERS\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 512\n",
        "NUM_HEADS = 4\n",
        "NUM_LAYERS = 4\n",
        "MLP_UNITS = [\n",
        "    PROJECTION_DIM * 2,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "MLP_HEAD_UNITS = [\n",
        "    2048,\n",
        "    1024,\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_wdyg2ukyeD"
      },
      "source": [
        "train_ds, val_ds, test_ds = tfds.load(\n",
        "    name=\"cifar10\",\n",
        "    data_dir=DATA_DIR,\n",
        "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
        "    as_supervised=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6iaIEIJkqP9"
      },
      "source": [
        "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTO)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gZwShY42gM2"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGTtuVR9nE3g"
      },
      "source": [
        "def get_train_augmentation_model():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Rescaling(1 / 255.0),\n",
        "            layers.Resizing(INPUT_SHAPE[0] + 20, INPUT_SHAPE[0] + 20),\n",
        "            layers.RandomCrop(IMAGE_SIZE, IMAGE_SIZE),\n",
        "            layers.RandomFlip(\"horizontal\"),\n",
        "        ],\n",
        "        name=\"train_data_augmentation\",\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_test_augmentation_model():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Rescaling(1 / 255.0),\n",
        "            layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        ],\n",
        "        name=\"test_data_augmentation\",\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsuO8pXk2lhC"
      },
      "source": [
        "# Patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jmZYNUnVF9"
      },
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size=PATCH_SIZE, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # Assuming the image has three channels each patch would be\n",
        "        # of size (patch_size, patch_size, 3).\n",
        "        self.resize = layers.Reshape((-1, patch_size * patch_size * 3))\n",
        "\n",
        "    def call(self, images):\n",
        "        # Create patches from the input images\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "\n",
        "        # Reshape the patches to (batch, num_patches, patch_area) and return it.\n",
        "        patches = self.resize(patches)\n",
        "        return patches\n",
        "\n",
        "    def show_patched_image(self, images, patches):\n",
        "        # This is a utility function which accepts a batch of images and its\n",
        "        # corresponding patches and help visualize one image and its patches\n",
        "        # side by side.\n",
        "        idx = np.random.choice(patches.shape[0])\n",
        "        print(f\"Index selected: {idx}.\")\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.imshow(keras.utils.array_to_img(images[idx]))\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        n = int(np.sqrt(patches.shape[1]))\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        for i, patch in enumerate(patches[idx]):\n",
        "            ax = plt.subplot(n, n, i + 1)\n",
        "            patch_img = tf.reshape(patch, (self.patch_size, self.patch_size, 3))\n",
        "            plt.imshow(keras.utils.img_to_array(patch_img))\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # Return the index chosen to validate it outside the method.\n",
        "        return idx\n",
        "\n",
        "    # taken from https://stackoverflow.com/a/58082878/10319735\n",
        "    def reconstruct_from_patch(self, patch):\n",
        "        # This utility function takes patches from a *single* image and\n",
        "        # reconstructs it back into the image. This is useful for the train\n",
        "        # monitor callback.\n",
        "        num_patches = patch.shape[0]\n",
        "        n = int(np.sqrt(num_patches))\n",
        "        patch = tf.reshape(patch, (num_patches, self.patch_size, self.patch_size, 3))\n",
        "        rows = tf.split(patch, n, axis=0)\n",
        "        rows = [tf.concat(tf.unstack(x), axis=1) for x in rows]\n",
        "        reconstructed = tf.concat(rows, axis=0)\n",
        "        return reconstructed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT3uNO27nfuY"
      },
      "source": [
        "# Get a batch of images.\n",
        "images, labels = next(iter(train_ds))\n",
        "\n",
        "# Augment the images.\n",
        "augmentation_model = get_train_augmentation_model()\n",
        "augmented_images = augmentation_model(images)\n",
        "\n",
        "# Define the patch layer.\n",
        "patch_layer = Patches()\n",
        "\n",
        "# Get the patches from the batched images.\n",
        "patches = patch_layer(images=augmented_images)\n",
        "\n",
        "# Now pass the images and the corresponding patches\n",
        "# to the `show_patched_image` method.\n",
        "random_index = patch_layer.show_patched_image(images=augmented_images, patches=patches)\n",
        "\n",
        "# Chose the same chose image and try reconstructing the patches\n",
        "# into the original image.\n",
        "image = patch_layer.reconstruct_from_patch(patches[random_index])\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C64Aqp4OG0TO"
      },
      "source": [
        "print(images.shape)\n",
        "print(patches.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ob3yvVA3E9u"
      },
      "source": [
        "# Patch Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XZH_aS4nqEE"
      },
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches=NUM_PATCHES, patch_size=PATCH_SIZE,\n",
        "        projection_dim=PROJECTION_DIM):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection_dim = projection_dim\n",
        "        self.patch_size = patch_size\n",
        "        \n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patches):\n",
        "        batch_size = tf.shape(patches)[0]\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkPSSCToFaK"
      },
      "source": [
        "# Create the patch encoder layer.\n",
        "patch_encoder = PatchEncoder()\n",
        "\n",
        "# Get the embeddings and positions.\n",
        "patch_embeddings = patch_encoder(patches=patches)\n",
        "\n",
        "print(patch_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuUfoaGpoUxN"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgr25Z2qoQb7"
      },
      "source": [
        "def mlp(x, dropout_rate, hidden_units):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfXKWaNCogWJ"
      },
      "source": [
        "# ViT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenLearner(layers.Layer):\n",
        "    def __init__(self, number_of_tokens, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.number_of_tokens = number_of_tokens\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        _, H, W, C = input_shape\n",
        "\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.conv_block = keras.Sequential([\n",
        "            layers.Conv2D(\n",
        "                filters=self.number_of_tokens,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=tf.nn.gelu,\n",
        "                padding=\"same\",\n",
        "                use_bias=False),\n",
        "            layers.Conv2D(\n",
        "                filters=self.number_of_tokens,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=tf.nn.gelu,\n",
        "                padding=\"same\",\n",
        "                use_bias=False),\n",
        "            layers.Conv2D(\n",
        "                filters=self.number_of_tokens,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=tf.nn.gelu,\n",
        "                padding=\"same\",\n",
        "                use_bias=False),\n",
        "            layers.Conv2D(\n",
        "                filters=self.number_of_tokens,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"sigmoid\",\n",
        "                padding=\"same\",\n",
        "                use_bias=False),\n",
        "            layers.Reshape((-1, self.number_of_tokens)),\n",
        "            layers.Permute((2, 1)),\n",
        "        ])\n",
        "\n",
        "        self.reshape_input = layers.Reshape((1, H*W, C))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # inputs == (B, H, W, C)\n",
        "        x = self.layer_norm(inputs)\n",
        "\n",
        "        # apply conv on the input\n",
        "        x = self.conv_block(x) # B, num_of_tokens, H*W\n",
        "\n",
        "        # reshape the input\n",
        "        inputs = self.reshape_input(inputs) # inputs == (B, 1, H*W, C)\n",
        "        x = tf.reduce_mean(x[..., tf.newaxis] * inputs, axis=2)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Oz10FLn6AsGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.random.normal((2, 4, 4, 256))\n",
        "token_learner = TokenLearner(8)\n",
        "out = token_learner(img)\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "id": "F_eLWWH-nAGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgufM6V3oXov"
      },
      "source": [
        "def get_encoder(num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM, \n",
        "    num_heads=NUM_HEADS, num_layers=NUM_LAYERS):\n",
        "    # inputs are the encoded patches\n",
        "    inputs = layers.Input((num_patches, projection_dim))\n",
        "    \n",
        "    x = inputs\n",
        "    for i in range(num_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x)\n",
        "\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, x])\n",
        "\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x2)\n",
        "\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=MLP_UNITS, dropout_rate=0.1)\n",
        "\n",
        "        # Skip connection 2.\n",
        "        x = layers.Add()([x3, x2])\n",
        "\n",
        "        if i == num_layers//2:\n",
        "            b, num, dims = x.shape\n",
        "\n",
        "            h = int(math.sqrt(num))\n",
        "            x = layers.Reshape((h, h, dims))(x)\n",
        "            x = TokenLearner(8)(x)\n",
        "    # return the model\n",
        "    return keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgKDfLxYQKu"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "# Get the encoder\n",
        "encoder = get_encoder()\n",
        "\n",
        "encoded_features = encoder(patch_embeddings)\n",
        "\n",
        "print(encoded_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Cw6NdwYjuC"
      },
      "source": [
        "# MLP Head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHIJQ4t0YCdm"
      },
      "source": [
        "def get_mlp_head(projection_dim=PROJECTION_DIM, num_classes=NUM_CLASSES):\n",
        "    inputs = layers.Input((8, projection_dim))\n",
        "    \n",
        "    x = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(inputs)\n",
        "    x = layers.Flatten()(x)\n",
        "    # Add MLP.\n",
        "    x = layers.Dense(units=1024, activation=tf.nn.gelu)(x)\n",
        "    x = layers.Dense(units=num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnni_NkFZ6Ej"
      },
      "source": [
        "mlp_head = get_mlp_head()\n",
        "preds = mlp_head(encoded_features)\n",
        "print(preds.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLFd3wwQohqB"
      },
      "source": [
        "class ViT(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_augmentation_model,\n",
        "        test_augmentation_model,\n",
        "        patch_layer,\n",
        "        patch_encoder,\n",
        "        encoder,\n",
        "        mlp_head,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.train_augmentation_model = train_augmentation_model\n",
        "        self.test_augmentation_model = test_augmentation_model\n",
        "        self.patch_layer = patch_layer\n",
        "        self.patch_encoder = patch_encoder\n",
        "        self.encoder = encoder\n",
        "        self.mlp_head = mlp_head\n",
        "\n",
        "    def calculate_loss(self, images, labels, test=False):\n",
        "        # Augment the input images.\n",
        "        if test:\n",
        "            augmented_images = self.test_augmentation_model(images)\n",
        "        else:\n",
        "            augmented_images = self.train_augmentation_model(images)\n",
        "\n",
        "        # Patch the augmented images.\n",
        "        patches = self.patch_layer(augmented_images)\n",
        "\n",
        "        # Encode the patches.\n",
        "        patch_embeddings = self.patch_encoder(patches)\n",
        "\n",
        "        encoded_features = self.encoder(patch_embeddings)\n",
        "        predictions = self.mlp_head(encoded_features)\n",
        "\n",
        "        total_loss = self.compiled_loss(labels, predictions)\n",
        "\n",
        "        return total_loss, predictions\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        # get the image and the label\n",
        "        images, labels = inputs\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            total_loss, predictions = self.calculate_loss(images, labels, test=False)\n",
        "\n",
        "        # Apply gradients.\n",
        "        train_vars = [\n",
        "            self.train_augmentation_model.trainable_variables,\n",
        "            self.patch_layer.trainable_variables,\n",
        "            self.patch_encoder.trainable_variables,\n",
        "            self.encoder.trainable_variables,\n",
        "            self.mlp_head.trainable_variables,\n",
        "        ]\n",
        "        grads = tape.gradient(total_loss, train_vars)\n",
        "        tv_list = []\n",
        "        for (grad, var) in zip(grads, train_vars):\n",
        "            for g, v in zip(grad, var):\n",
        "                tv_list.append((g, v))\n",
        "        self.optimizer.apply_gradients(tv_list)\n",
        "\n",
        "        # Report progress.\n",
        "        self.compiled_metrics.update_state(labels, predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, inputs):\n",
        "        # get the image and the label\n",
        "        images, labels = inputs\n",
        "\n",
        "        # compute the predictions and the loss\n",
        "        total_loss, predictions = self.calculate_loss(images, labels, test=True)\n",
        "\n",
        "        # Update the trackers.\n",
        "        self.compiled_metrics.update_state(labels, predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_c2_j0PrtCT"
      },
      "source": [
        "train_augmentation_model = get_train_augmentation_model()\n",
        "test_augmentation_model = get_test_augmentation_model()\n",
        "patch_layer = Patches()\n",
        "patch_encoder = PatchEncoder()\n",
        "encoder = get_encoder()\n",
        "mlp_head = get_mlp_head()\n",
        "\n",
        "vit_model = ViT(\n",
        "    train_augmentation_model=train_augmentation_model,\n",
        "    test_augmentation_model=test_augmentation_model,\n",
        "    patch_layer=patch_layer,\n",
        "    patch_encoder=patch_encoder,\n",
        "    encoder = encoder,\n",
        "    mlp_head = mlp_head\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx0iKceBr2p3"
      },
      "source": [
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "# Compile and pretrain the model.\n",
        "vit_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "history = vit_model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7RnoiLYs1EK"
      },
      "source": [
        "_, accuracy, top_5_accuracy = vit_model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}